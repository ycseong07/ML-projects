{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sX4U5VeGYoUd"
   },
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROGdQZelYzdo"
   },
   "source": [
    "## 감성분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnFg7bySY8Ht"
   },
   "source": [
    "###  데이터셋 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oldd1-7wy1Bp"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(SEED)\n\u001b[1;32m      9\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mdeterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mtorchtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspacy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m label \u001b[38;5;241m=\u001b[39m torchtext\u001b[38;5;241m.\u001b[39mlegacy\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mLabelField(dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat)\n",
      "File \u001b[0;32m~/python3-venv/lib/python3.8/site-packages/torchtext-0.10.0a0+4da1de3-py3.8-linux-aarch64.egg/torchtext/legacy/data/field.py:161\u001b[0m, in \u001b[0;36mField.__init__\u001b[0;34m(self, sequential, use_vocab, init_token, eos_token, fix_length, dtype, preprocessing, postprocessing, lower, tokenize, tokenizer_language, include_lengths, batch_first, pad_token, unk_token, pad_first, truncate_first, stop_words, is_target)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# store params to construct tokenizer for serialization\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# in case the tokenizer isn't picklable (e.g. spacy)\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer_args \u001b[38;5;241m=\u001b[39m (tokenize, tokenizer_language)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenize \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_language\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_lengths \u001b[38;5;241m=\u001b[39m include_lengths\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;241m=\u001b[39m batch_first\n",
      "File \u001b[0;32m~/python3-venv/lib/python3.8/site-packages/torchtext-0.10.0a0+4da1de3-py3.8-linux-aarch64.egg/torchtext/data/utils.py:113\u001b[0m, in \u001b[0;36mget_tokenizer\u001b[0;34m(tokenizer, language)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspacy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m             spacy \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(language)\n",
      "File \u001b[0;32m~/python3-venv/lib/python3.8/site-packages/spacy/__init__.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prefer_gpu, require_gpu, require_cpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/python3-venv/lib/python3.8/site-packages/thinc/api.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, registry, ConfigValidationError\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normal_init, uniform_init, glorot_uniform_init, zero_init\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_normal_init\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalCrossentropy, L2Distance, CosineDistance\n",
      "File \u001b[0;32m~/python3-venv/lib/python3.8/site-packages/thinc/initializers.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, cast\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ops\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FloatsXd, Shape\n",
      "File \u001b[0;32m~/python3-venv/lib/python3.8/site-packages/thinc/backends/__init__.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ops\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcupy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CupyOps, has_cupy\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumpyOps\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cupy_allocators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cupy_tensorflow_allocator, cupy_pytorch_allocator\n",
      "File \u001b[0;32m~/python3-venv/lib/python3.8/site-packages/thinc/backends/cupy_ops.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ops\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumpyOps\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _custom_kernels\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeviceTypes\n",
      "File \u001b[0;32m~/python3-venv/lib/python3.8/site-packages/thinc/backends/numpy_ops.pyx:1\u001b[0m, in \u001b[0;36minit thinc.backends.numpy_ops\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "# data 생성\n",
    "# From torchText 0.9.0: torchtext.data.Field -> torchtext.legacy.data.Field\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "text = torchtext.legacy.data.Field(tokenize = 'spacy')\n",
    "label = torchtext.legacy.data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0EMdwgEEROI"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 다운로드 및 분할\n",
    "\n",
    "from torchtext import datasets\n",
    "\n",
    "trn_data, test_data = datasets.IMDB.splits(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hQmxsDMzEabv"
   },
   "outputs": [],
   "source": [
    "# Dataset volume 확인\n",
    "\n",
    "print('Number of training examples:', len(trn_data))\n",
    "print('Number of testing examples:', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcMXiOjvEcXv"
   },
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "\n",
    "print(vars(trn_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwLn0DIUY6TF"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trn_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# training set을 다시 train/dev set으로 분리\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# default value는 7:3\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata type: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtrn_data\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrn data volume\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trn_data))\n\u001b[1;32m      8\u001b[0m train_data, valid_data \u001b[38;5;241m=\u001b[39m trn_data\u001b[38;5;241m.\u001b[39msplit(random_state \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mseed(SEED))\u001b[38;5;66;03m#, split_ratio=0.9)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trn_data' is not defined"
     ]
    }
   ],
   "source": [
    "# training set을 다시 train/dev set으로 분리\n",
    "# default value는 7:3\n",
    "import random\n",
    "\n",
    "print(\"data type: \", trn_data)\n",
    "print(\"trn data volume\", len(trn_data))\n",
    "\n",
    "train_data, valid_data = trn_data.split(random_state = random.seed(SEED))#, split_ratio=0.9)\n",
    "print(\"splited trn data volume: \", len(train_data))\n",
    "print(\"splited dev data volume: \", len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yNBJCBj1Y9UJ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 최종 데이터 볼륨 확인\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of training examples: \u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_data\u001b[49m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of validation examples:  \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(valid_data))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of testing examples:  \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test_data))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# 최종 데이터 볼륨 확인\n",
    "\n",
    "print('Number of training examples: ',  len(train_data))\n",
    "print('Number of validation examples:  ', len(valid_data))\n",
    "print('Number of testing examples:  ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-9G3Kanyb4-"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 빈도를 고려하여 25,000 단어만 사용하기\u001b[39;00m\n\u001b[1;32m      3\u001b[0m MAX_VOCAB_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25000\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mbuild_vocab(train_data, max_size \u001b[38;5;241m=\u001b[39m MAX_VOCAB_SIZE)\n\u001b[1;32m      6\u001b[0m label\u001b[38;5;241m.\u001b[39mbuild_vocab(train_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "# 빈도를 고려하여 25,000 단어만 사용하기\n",
    "\n",
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "text.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "label.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAcFkMrr4amt"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 단어,  label  수 확인하기\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# <unk>, <pad> 포함\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnique tokens in TEXT vocabulary: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mvocab))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnique tokens in LABEL vocabulary: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(label\u001b[38;5;241m.\u001b[39mvocab))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "# 단어,  label  수 확인하기\n",
    "# <unk>, <pad> 포함\n",
    "\n",
    "print('Unique tokens in TEXT vocabulary: ', len(text.vocab))\n",
    "print('Unique tokens in LABEL vocabulary: ', len(label.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CMox9a-s4pCy"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 등장 빈도가 높은 10개 단어 확인\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mfreqs\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "# 등장 빈도가 높은 10개 단어 확인\n",
    "\n",
    "print(text.vocab.freqs.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hIPOnzU0KA-T"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# string to int, int to string\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mitos[:\u001b[38;5;241m10\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(label\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mstoi)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "# string to int, int to string\n",
    "\n",
    "print(text.vocab.itos[:10])\n",
    "print(label.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xu1LXNGAYiqN"
   },
   "outputs": [],
   "source": [
    "# dataloader 생성하기\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ON_gCzwfZcw8"
   },
   "source": [
    "###  RNN 모델 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpoFVnThZe3R"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # num of vocab x embedding 차원\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        # RNN 선언\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        # 분류기\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        #  text = [sent len, batch size]\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #  embedded = [sent len, batch size, emb dim]\n",
    "        out, hidden = self.rnn(embedded)\n",
    "        \n",
    "        # return self.fc(hidden.squeeze(0))\n",
    "        return self.fc(out[-1, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VlTievL4TLGX"
   },
   "outputs": [],
   "source": [
    "#  ...에 대해서 알아보기\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "a = torch.rand(3, 5, 5)\n",
    "print(a.size())\n",
    "\n",
    "b = a[1, ...]\n",
    "print(b.size())\n",
    "\n",
    "c = a[1, :, :]\n",
    "print(c.size())\n",
    "\n",
    "print(b==c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T51c7bNUagRk"
   },
   "outputs": [],
   "source": [
    "input_dim = len(text.vocab)\n",
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "\n",
    "model = RNN(input_dim, embedding_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJjE0v6papfs"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('The model has {:,} trainable parameters'.format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5CYME_FrbEsV"
   },
   "source": [
    "### 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Au4p8WWoa2tG"
   },
   "outputs": [],
   "source": [
    "# optimizer 지정\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DHWzeIB9bKzI"
   },
   "outputs": [],
   "source": [
    "# loss 함수 지정\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Um3jYMRHbRgR"
   },
   "outputs": [],
   "source": [
    "# device 지정\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "arR4ITZRdkKs"
   },
   "outputs": [],
   "source": [
    "# round, sigmoid 함수 확인\n",
    "\n",
    "a = torch.tensor([-0.02, 0.4, -0.7, 0.9, 0.99])\n",
    "b = torch.sigmoid(a)\n",
    "print(b)\n",
    "\n",
    "c = torch.round(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "noHqgljmbZQD"
   },
   "outputs": [],
   "source": [
    "# Accuracy 산출 함수\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = rounded_preds.eq(y).float()\n",
    "    acc = correct.sum() / len(y)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyOBTM4rf2gi"
   },
   "outputs": [],
   "source": [
    "#  학습 함수\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    # 학습 지정\n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # text, label = batch.text.to(device), batch.label.to(device)\n",
    "                \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20Q59gEYf4cr"
   },
   "outputs": [],
   "source": [
    "#  평가 함수\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3AAvmHGf6Lw"
   },
   "outputs": [],
   "source": [
    "#  시간 측정 함수\n",
    "\n",
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ujyy5rwf7YK"
   },
   "outputs": [],
   "source": [
    "#  실제 학습 부분\n",
    "\n",
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, N_EPOCHS+1):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print('Epoch: {:02} | Epoch Time: {}m {}s'.format(epoch, epoch_mins, epoch_secs))\n",
    "    print('\\tTrain Loss: {:.3f} | Train Acc: {:.2f}'.format(train_loss, train_acc*100))\n",
    "    print('\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}'.format(valid_loss, valid_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPgHLPyyf8sE"
   },
   "outputs": [],
   "source": [
    "#  저장된 모델 load후 테스트 진행\n",
    "\n",
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print('Test Loss: {:.3f} | Test Acc: {:.2f}'.format(test_loss, test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVaOxmY6quqe"
   },
   "source": [
    "###  LSTM 모델 구성하기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYvbhwFjtAQH"
   },
   "outputs": [],
   "source": [
    "# 길이 정보를 포함하는 데이터 생성하기\n",
    "\n",
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "text = data.Field(tokenize = 'spacy', include_lengths = True)\n",
    "label = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NriJn2dwtIvI"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 다운로드 및 분할\n",
    "\n",
    "from torchtext import datasets\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQz6GxrOtMdE"
   },
   "outputs": [],
   "source": [
    "# training set에서 validation set 분할하기\n",
    "import random\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6qWWWJXxtUob"
   },
   "outputs": [],
   "source": [
    "# 25,000 단어만 고려하기\n",
    "\n",
    "max_vocab_size = 25000\n",
    "\n",
    "text.build_vocab(train_data, max_size = max_vocab_size)\n",
    "\n",
    "label.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BLaOE8Nr-3d"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J7jYTj-WnNlu"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional\n",
    "                           )\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, 64)\n",
    "        self.fc2 = nn.Linear(64, output_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #  text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #  embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #  pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        #  unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        # output: (seq_length, batch size, hidden dim * num directions)\n",
    "        \n",
    "        output = self.relu(output)\n",
    "        output = self.dropout(self.fc1(output[-1, ...]))\n",
    "            \n",
    "        return self.fc2(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0L56vJrK3ToW"
   },
   "outputs": [],
   "source": [
    "# pack_padded_sequence, pad_packed_sequence 확인\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "seq = torch.tensor([[1,2,0], [3,0,0], [4,5,6]])\n",
    "lens = [2, 1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cy0Ygu133cii"
   },
   "outputs": [],
   "source": [
    "packed = pack_padded_sequence(seq, lens, batch_first=True, enforce_sorted=False)\n",
    "print(packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jotxy0g43e1v"
   },
   "outputs": [],
   "source": [
    "seq_unpacked, lens_unpacked = pad_packed_sequence(packed, batch_first=True)\n",
    "print(seq_unpacked)\n",
    "print(lens_unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8HzRA2Xqxxc"
   },
   "outputs": [],
   "source": [
    "# model 선언\n",
    "\n",
    "INPUT_DIM = len(text.vocab)\n",
    "EMBEDDING_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = text.vocab.stoi[text.pad_token]\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukaV_MFUqzRC"
   },
   "outputs": [],
   "source": [
    "# 모델 파라미터 수\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QOeKnosCq3QC"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6wEX9LjZrG0V"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gxt02JHkrRrR"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmYq1SfjrUMi"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text, text_lengths = batch.text\n",
    "\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hloXktUjq_XZ"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7SNcWkiwWN5"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut2-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V9Di4u-HCNLH"
   },
   "source": [
    "## RNN을 통한 이미지 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "43ivjeRiCQfu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_cjKrKG4EJU3"
   },
   "outputs": [],
   "source": [
    "# dataset 생성\n",
    "\n",
    "train_dataset = dsets.MNIST(root='../data/RNN_AE', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='../data/RNN_AE', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99b_ziy6EM9w"
   },
   "outputs": [],
   "source": [
    "# data loader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wS7AJ-WEXRT"
   },
   "outputs": [],
   "source": [
    "# RNN model 생성\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layer, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.num_layer = num_layer\n",
    "\n",
    "        # RNN Cell 선언\n",
    "        # batch_first=True > (batch_dim, seq_dim, input_dim)\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, num_layer, batch_first=True)\n",
    "\n",
    "        # Dense layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 첫 번째 hidden state (h0), cell state (c0) 지정\n",
    "        # (num_layer, batch_size, hidden_dim)\n",
    "        h0 = torch.rand(self.num_layer, x.size(0), self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.num_layer, x.size(0), self.hidden_dim).to(device)\n",
    "        out, hn = self.rnn(x, (h0, c0))\n",
    "\n",
    "        # out size\n",
    "        # out.size() --> 64, 28, 10\n",
    "        # out[:, -1, :] --> 64, 10 --> 최종 결과물만!\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 64, 10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lbLNaOLEja6"
   },
   "outputs": [],
   "source": [
    "# model 상속\n",
    "\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "num_layer = 1\n",
    "output_dim = 10\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, num_layer, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMw66lrF4qo3"
   },
   "outputs": [],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yWiqoA2VEx9P"
   },
   "outputs": [],
   "source": [
    "# optimizer 지정\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Pq6k3usNrqE"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIXxC9T9QyzR"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        # GPU사용을 위한 설정\n",
    "        images, labels = images.squeeze(1).to(device), labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() --> 100, 10\n",
    "        outputs = model(images)\n",
    "\n",
    "        # loss 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # gradients 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    # Calculate Accuracy         \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Iterate through test dataset\n",
    "    for images, labels in test_loader:\n",
    "        # GPU사용을 위한 설정\n",
    "        images, labels = images.squeeze(1).to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # 전체 데이터 수 구하기\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # 정답 수 더하기\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Print Loss\n",
    "    print('Epoch: {}. Loss: {:.3f}. Accuracy: {}'.format(epoch, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u4uEliiPA35O"
   },
   "source": [
    "# Auto Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HTml291PA7ZW"
   },
   "source": [
    "## Basic AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_fOtqKnrXaD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XR_JQ0Yz4Rfc"
   },
   "outputs": [],
   "source": [
    "# dataloader 생성\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "dataset = MNIST('../data/RNN_AE', download=True, transform=img_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wb3KN_v_5GLo"
   },
   "outputs": [],
   "source": [
    "# AE model 생성\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(64, 12), \n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(12, 3)\n",
    "            )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Tanh()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "model = autoencoder()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9-AGUYVBrgK"
   },
   "outputs": [],
   "source": [
    "# GPU 사용하기\n",
    "\n",
    "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UwgpN3BZB7Qb"
   },
   "outputs": [],
   "source": [
    "# optimizer, loss function 지정\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfM3qRI2C5rr"
   },
   "outputs": [],
   "source": [
    "# 시각화\n",
    "\n",
    "%matplotlib inline\n",
    "def show(origin, reconstructed):\n",
    "    origin = origin.cpu().data\n",
    "    origin = origin.view(origin.size(0), 28, 28)[0, ...]\n",
    "\n",
    "    reconstructed = reconstructed.cpu().data\n",
    "    reconstructed = reconstructed.view(reconstructed.size(0), 28, 28)[0, ...]\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(origin)\n",
    "    plt.title(\"Original\")\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(reconstructed)\n",
    "    plt.title(\"Reconstructed\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBUk-ImrCVS2"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    for (imgs, _) in dataloader:\n",
    "        img = imgs.view(imgs.size(0), -1).to(device)\n",
    "\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch, num_epochs, loss.data))\n",
    "    show(img, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAabliTXMj5M"
   },
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49YK1r_tDARi"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_sHg2ewwMuuK"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MM3KHU7IMwZt"
   },
   "outputs": [],
   "source": [
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# load the training and test datasets\n",
    "train_data = datasets.CIFAR10(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root='data', train=False,\n",
    "                                  download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9eWkYvRMNypp"
   },
   "outputs": [],
   "source": [
    "# Create training and test dataloaders\n",
    "\n",
    "# batch size 지정\n",
    "batch_size = 64\n",
    "\n",
    "# 데이터로더 지정\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYmD828CMyrw"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 시각화\n",
    "def imshow(img):\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
    "    \n",
    "# label 명시\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nz6rV_hGM4_H"
   },
   "outputs": [],
   "source": [
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(\"Before: \", type(images))\n",
    "images = images.numpy() # display를 위한 형변형\n",
    "print(\"After: \", type(images))\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "# display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TrvCAHC3M6y4"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        ## encoder layers ##\n",
    "        # conv layer (depth from 3 --> 16), 3x3 kernels\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)  \n",
    "        # conv layer (depth from 16 --> 4), 3x3 kernels\n",
    "        self.conv2 = nn.Conv2d(16, 4, 3, padding=1)\n",
    "        # pooling layer (kerner size, stride)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        ## decoder layers ##\n",
    "        ## Upsampling\n",
    "        self.t_conv1 = nn.ConvTranspose2d(4, 16, 2, stride=2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(16, 3, 2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## encode ##\n",
    "        # hidden layers with relu activation function\n",
    "        # & maxpooling after\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        # add second hidden layer\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        ## decode ##\n",
    "        # add transpose conv layers, with relu activation function\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        # output layer (with sigmoid for scaling from 0 to 1)\n",
    "        x = F.sigmoid(self.t_conv2(x))\n",
    "                \n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = ConvAutoencoder()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PAUg5DmDNUge"
   },
   "outputs": [],
   "source": [
    "# loss function 지정\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# optimizer 지정\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0UA59rq3BDW"
   },
   "outputs": [],
   "source": [
    "# GPU 사용하기\n",
    "\n",
    "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2Idp1sMNbJ4"
   },
   "outputs": [],
   "source": [
    "# 전체 epoch 지정\n",
    "n_epochs = 50\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for (images, _) in train_loader:\n",
    "        images = images.to(device)\n",
    "        # gradients 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, images)\n",
    "\n",
    "        # backward pass: gradients 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # training loss 합산\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "            \n",
    "    # 평균 loss 산출\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch, \n",
    "        train_loss\n",
    "        ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_msSMCRNgL5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# obtain one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images)\n",
    "# prep images for display\n",
    "images = images.cpu().numpy()\n",
    "\n",
    "\n",
    "# output is resized into a batch of iages\n",
    "output = output.view(batch_size, 3, 32, 32)\n",
    "# use detach when it's an output that requires_grad\n",
    "output = output.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(output[idx])\n",
    "    ax.set_title(classes[labels[idx]])\n",
    "    \n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_pickle(\"../data/RNN_AE/LSWMD_sample.pkl\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualization\n",
    "r_list = list(np.arange(100))\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 10, ncols = 10, figsize=(30, 30))\n",
    "ax = ax.ravel(order='C')\n",
    "tmp_num = 0\n",
    "for i in r_list:\n",
    "    img = df['waferMap'].values[i]\n",
    "    ax[tmp_num].imshow(img, cmap = plt.cm.Reds)\n",
    "    ax[tmp_num].set_xticks([])\n",
    "    ax[tmp_num].set_yticks([])\n",
    "    tmp_num += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset for corolization\n",
    "class customDataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        # dataset 길이 측정\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # image resize > tensor 변형\n",
    "        x_3d = np.repeat(self.x[idx][:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "        colorized = np.where(\n",
    "            x_3d==0, np.array([255, 255, 255], dtype=np.uint8),(\n",
    "                np.where(\n",
    "                    x_3d==1, np.array([255, 204, 204], dtype=np.uint8),(\n",
    "                        np.array([51, 0, 0], dtype=np.uint8))))) ## 0/1/2 일때,\n",
    "        x = self.transform(colorized)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model\n",
    "class Interpolate(nn.Module):\n",
    "    def __init__(self, scale_factor, mode):\n",
    "        super(Interpolate, self).__init__()\n",
    "        self.interp = nn.functional.interpolate\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.interp(x, scale_factor=self.scale_factor, mode=self.mode)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CAE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # Interpolate(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(64, 32, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            Interpolate(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(32, 16, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            Interpolate(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(16, 3, 1, 1, 0),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)  # encode.shape = torch.Size([BS, 64, 4, 4])\n",
    "        decoded = self.decoder(encoded) # decode.shape = torch.Size([BS, 1, 32, 32])\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# construct dataset\n",
    "dataset = customDataset(df['waferMap'].values)\n",
    "\n",
    "# dataset volumn 계산\n",
    "num_train = int(0.7 * len(dataset))\n",
    "num_dev = int(0.3 * len(dataset))\n",
    "\n",
    "# split dataset\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [num_train + 1, num_dev])\n",
    "\n",
    "# construct dataloader\n",
    "dataloader_trn = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "dataloader_dev = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "autoencoder = CAE().to(device)\n",
    "print(autoencoder)\n",
    "\n",
    "print('Training Data 수 : {}'.format(len(train_set)))\n",
    "print('Validation Data 수 : {}'.format(len(val_set)))\n",
    "print('Batch Size : {}'.format(batch_size))\n",
    "print('Train Mini Batch 개수 : {}'.format(len(dataloader_trn)))\n",
    "print('Validation Mini Batch 개수 : {}'.format(len(dataloader_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an optimizer and criterion\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "best_loss = 1000\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    _dev_loss = 0.0\n",
    "\n",
    "    autoencoder.train()\n",
    "    for i, data in enumerate(dataloader_trn):\n",
    "        inputs = data.to(device)\n",
    "        # ============ Forward ============\n",
    "        _, outputs = autoencoder(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        # ============ Backward ============\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ============ Logging ============\n",
    "        running_loss += loss.data\n",
    "        if i % 10 == 9:\n",
    "            print(f'[Trn] {epoch+1}/{epochs}, {i+1}/{len(dataloader_trn)} \\\n",
    "                loss: {(running_loss/20):.5f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Validate Model\n",
    "    autoencoder.eval()\n",
    "    for idx, data in enumerate(dataloader_dev):\n",
    "        # step progress\n",
    "        inputs = data.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # ============ Forward ============\n",
    "            _, outputs = autoencoder(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "\n",
    "            # ============ Logging ============\n",
    "            _dev_loss += loss\n",
    "            dev_loss = _dev_loss/(idx+1)\n",
    "            if idx % 50 == 49:\n",
    "                print(f'[Dev] {epoch+1}/{epochs}, {idx+1}/{len(dataloader_dev)} \\\n",
    "                    loss: {dev_loss:.5f}')\n",
    "\n",
    "    if dev_loss < best_loss:\n",
    "        best_loss = dev_loss\n",
    "        # print(f\"The best model is saved / Loss: {dev_loss:.5f}\")\n",
    "        torch.save({\n",
    "            'model': autoencoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'trained_epoch': epoch,\n",
    "        }, os.path.join('./best_model', 'autoencoder.pkl'))\n",
    "        \n",
    "        save_image(\n",
    "            torchvision.utils.make_grid(outputs),\n",
    "            os.path.join('./reconstructed', f'reconstructed_epoch_{epoch}.jpg'),\n",
    "            normalize=True\n",
    "            )\n",
    "        save_image(\n",
    "            torchvision.utils.make_grid(inputs),\n",
    "            os.path.join('./reconstructed', f'original_epoch.jpg'),\n",
    "            normalize=True\n",
    "            )\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2020_hynix_RNN_AE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
